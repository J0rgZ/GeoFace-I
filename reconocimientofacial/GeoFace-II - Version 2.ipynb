{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh1Dud7gyQb2"
   },
   "source": [
    "# **Notebook Completo para Reconocimiento Facial (Colab + Firebase + Flutter)**\n",
    "## Celda 1: Configuraci√≥n Inicial e Instalaci√≥n de Dependencias\n",
    "Prop√≥sito: Esta celda prepara el entorno. Primero, subes tu clave de Firebase para que el script pueda acceder a tus datos. Luego, instala todas las librer√≠as necesarias (firebase-admin para conectar con Firebase, deepface para el reconocimiento facial y pyngrok para crear la API p√∫blica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "executionInfo": {
     "elapsed": 17607,
     "status": "ok",
     "timestamp": 1762826417342,
     "user": {
      "displayName": "Jorge Luis BRICE√ëO D√çAZ",
      "userId": "05586719358853567762"
     },
     "user_tz": 300
    },
    "id": "GYUVwEbCyeqt",
    "outputId": "27863641-5618-4008-86ff-12bd584a0edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por favor, sube el archivo JSON de tu cuenta de servicio de Firebase.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-b3f01fdd-aecd-447a-a2e5-998163345bfe\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-b3f01fdd-aecd-447a-a2e5-998163345bfe\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving geoface-c53eb-firebase-adminsdk-fbsvc-dbb0ac7ff5.json to geoface-c53eb-firebase-adminsdk-fbsvc-dbb0ac7ff5.json\n",
      "\n",
      "‚úÖ Archivo 'geoface-c53eb-firebase-adminsdk-fbsvc-dbb0ac7ff5.json' subido correctamente.\n",
      "\n",
      "Instalando dependencias... (Esto puede tardar un par de minutos)\n",
      "‚úÖ Dependencias instaladas.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Celda 1: Configuraci√≥n e Instalaci√≥n\n",
    "# ==============================================================================\n",
    "# Prop√≥sito: Preparar el entorno de Colab, subir la clave de Firebase\n",
    "# e instalar todas las librer√≠as necesarias.\n",
    "# ==============================================================================\n",
    "\n",
    "# Paso 1: Subir la clave de servicio de Firebase\n",
    "# ------------------------------------------------------------------------------\n",
    "# Al ejecutar esta celda, aparecer√° un bot√≥n para que subas el archivo .json\n",
    "# que descargaste desde la configuraci√≥n de tu proyecto de Firebase.\n",
    "# Este archivo es esencial para que el script se autentique de forma segura.\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Por favor, sube el archivo JSON de tu cuenta de servicio de Firebase.\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Guardamos el nombre del archivo subido para usarlo m√°s adelante\n",
    "key_filename = list(uploaded.keys())[0]\n",
    "print(f\"\\n‚úÖ Archivo '{key_filename}' subido correctamente.\")\n",
    "\n",
    "\n",
    "# Paso 2: Instalar las librer√≠as de Python necesarias\n",
    "# ------------------------------------------------------------------------------\n",
    "# - firebase-admin: La librer√≠a oficial de Google para interactuar con Firebase.\n",
    "# - deepface: Una potente librer√≠a que simplifica el reconocimiento facial.\n",
    "# - pyngrok: Herramienta para crear una URL p√∫blica y conectar Flutter con Colab.\n",
    "# - opencv-python-headless, numpy, Pillow: Librer√≠as para el an√°lisis de im√°genes\n",
    "#   y la detecci√≥n de spoofing (fotos de fotos).\n",
    "\n",
    "print(\"\\nInstalando dependencias... (Esto puede tardar un par de minutos)\")\n",
    "!pip install firebase-admin deepface pyngrok opencv-python-headless numpy Pillow --quiet\n",
    "print(\"‚úÖ Dependencias instaladas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04yCUk_0yrEL"
   },
   "source": [
    "## Celda 2: L√≥gica Principal (Conexi√≥n a Firebase y Funciones de IA)\n",
    "### Prop√≥sito: Aqu√≠ reside el \"cerebro\" de nuestro sistema.\n",
    "1. Inicializa Firebase: Usa la clave que subiste para conectar con tu proyecto.\n",
    "2. Sincroniza la Base de Datos Facial: Lee la colecci√≥n biometricos de tu Firestore, descarga cada foto de empleado desde Cloud Storage y la organiza en una estructura de carpetas local (DB_PATH/empleadoId/foto.jpg). DeepFace usar√° esta estructura para saber a qui√©n pertenece cada rostro.\n",
    "3. Define la Funci√≥n de Identificaci√≥n: Crea la funci√≥n identificar_empleado que toma una imagen nueva (la que enviar√° tu app) y la compara contra la base de datos local para encontrar la mejor coincidencia y devolver el empleadoId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1762826447772,
     "user": {
      "displayName": "Jorge Luis BRICE√ëO D√çAZ",
      "userId": "05586719358853567762"
     },
     "user_tz": 300
    },
    "id": "bcuCi62My3-2",
    "outputId": "9a9c5a4b-f958-4761-d134-a6323295b400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è Firebase App ya estaba inicializada.\n",
      "\n",
      "üîÑ Sincronizando base de datos...\n",
      "‚úÖ Sincronizaci√≥n completada: 0 im√°genes para 4 empleados.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Celda 2: L√≥gica Principal - Conexi√≥n a Firebase y Funciones de IA (Versi√≥n Mejorada con Anti-Spoofing Avanzado)\n",
    "# ==============================================================================\n",
    "# Prop√≥sito: Conectar con Firebase, descargar fotos, y definir funciones de IA\n",
    "# que incluyen un robusto sistema anti-spoofing antes del reconocimiento facial.\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "from deepface import DeepFace\n",
    "# --- NUEVAS LIBRER√çAS NECESARIAS PARA ANTI-SPOOFING ---\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageStat\n",
    "\n",
    "# --- CONFIGURACI√ìN GLOBAL ---\n",
    "SERVICE_ACCOUNT_KEY = key_filename\n",
    "DB_PATH = \"employee_face_db\"\n",
    "\n",
    "# --- FUNCIONES DE INFRAESTRUCTURA (Firebase y Sincronizaci√≥n) ---\n",
    "\n",
    "def initialize_firebase():\n",
    "    \"\"\"Inicializa la app de Firebase usando la clave de servicio.\"\"\"\n",
    "    try:\n",
    "        if not firebase_admin._apps:\n",
    "            cred = credentials.Certificate(SERVICE_ACCOUNT_KEY)\n",
    "            firebase_admin.initialize_app(cred)\n",
    "            print(\"‚úÖ Conexi√≥n con Firebase establecida correctamente.\")\n",
    "        else:\n",
    "            print(\"‚ÑπÔ∏è Firebase App ya estaba inicializada.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al inicializar Firebase: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def sync_face_database_from_firestore():\n",
    "    print(\"\\nüîÑ Sincronizando base de datos...\")\n",
    "    if os.path.exists(DB_PATH):\n",
    "        shutil.rmtree(DB_PATH)\n",
    "    os.makedirs(DB_PATH, exist_ok=True)\n",
    "    db = firestore.client()\n",
    "    docs = db.collection('biometricos').stream()\n",
    "    image_count = 0\n",
    "    employee_folders = set()\n",
    "    \n",
    "    for doc in docs:\n",
    "        data = doc.to_dict()\n",
    "        empleado_id = data.get('empleadoId')\n",
    "        # CORRECCI√ìN: Buscar 'datosFaciales' (plural, array) en lugar de 'datoFacial' (singular)\n",
    "        datos_faciales = data.get('datosFaciales', [])\n",
    "        \n",
    "        if not empleado_id or not datos_faciales:\n",
    "            if not empleado_id:\n",
    "                print(f\"   ‚ö†Ô∏è  Documento {doc.id} sin empleadoId, omitiendo...\")\n",
    "            elif not datos_faciales:\n",
    "                print(f\"   ‚ö†Ô∏è  Empleado {empleado_id} sin datosFaciales, omitiendo...\")\n",
    "            continue\n",
    "        \n",
    "        # Crear directorio para el empleado\n",
    "        employee_dir = os.path.join(DB_PATH, empleado_id)\n",
    "        os.makedirs(employee_dir, exist_ok=True)\n",
    "        employee_folders.add(empleado_id)\n",
    "        \n",
    "        # CORRECCI√ìN: Iterar sobre todas las URLs del array datosFaciales\n",
    "        if isinstance(datos_faciales, list):\n",
    "            for idx, image_url in enumerate(datos_faciales):\n",
    "                if not image_url or not isinstance(image_url, str):\n",
    "                    continue\n",
    "                try:\n",
    "                    response = requests.get(image_url, timeout=10)\n",
    "                    if response.status_code == 200:\n",
    "                        # Guardar cada imagen con un nombre √∫nico (√≠ndice + UUID del documento)\n",
    "                        filename = f\"{doc.id}_{idx}.jpg\"\n",
    "                        filepath = os.path.join(employee_dir, filename)\n",
    "                        with open(filepath, 'wb') as f:\n",
    "                            f.write(response.content)\n",
    "                        image_count += 1\n",
    "                        print(f\"   ‚úÖ Descargada imagen {idx+1}/{len(datos_faciales)} para empleado {empleado_id}\")\n",
    "                    else:\n",
    "                        print(f\"   ‚ö†Ô∏è  Error HTTP {response.status_code} al descargar {image_url}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ö†Ô∏è  Excepci√≥n al descargar imagen {idx+1} de {empleado_id}: {e}\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  datosFaciales no es un array para empleado {empleado_id}, tipo: {type(datos_faciales)}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Sincronizaci√≥n completada: {image_count} im√°genes para {len(employee_folders)} empleados.\")\n",
    "    \n",
    "    # Eliminar cache de DeepFace si existe para forzar regeneraci√≥n\n",
    "    cache_file = os.path.join(DB_PATH, \"representations_arcface.pkl\")\n",
    "    if os.path.exists(cache_file):\n",
    "        os.remove(cache_file)\n",
    "        print(\"‚ÑπÔ∏è Cache (.pkl) eliminado para forzar regeneraci√≥n con nuevas im√°genes.\")\n",
    "\n",
    "\n",
    "# --- NUEVAS FUNCIONES ANTI-SPOOFING (An√°lisis de Imagen Completa) ---\n",
    "\n",
    "def detectar_foto_de_foto(ruta_imagen):\n",
    "    \"\"\"\n",
    "    Detecta si una imagen es una foto de una pantalla o papel usando an√°lisis de imagen.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Cargar la imagen con OpenCV\n",
    "        img_cv = cv2.imread(ruta_imagen)\n",
    "        if img_cv is None:\n",
    "            return False, {\"error\": \"No se pudo cargar la imagen con OpenCV.\"}\n",
    "\n",
    "        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Puntuaci√≥n y razones para la decisi√≥n\n",
    "        score_spoofing = 0\n",
    "        razones = []\n",
    "\n",
    "        # T√âCNICA 1: Detecci√≥n de patrones de Moir√© (comunes en fotos de pantallas)\n",
    "        f_transform = np.fft.fft2(gray)\n",
    "        f_shift = np.fft.fftshift(f_transform)\n",
    "        magnitude_spectrum = 20 * np.log(np.abs(f_shift))\n",
    "        # Los patrones de Moir√© crean picos de alta frecuencia muy marcados\n",
    "        picos_altos = np.sum(magnitude_spectrum > np.mean(magnitude_spectrum) * 1.5)\n",
    "        if picos_altos > (gray.shape[0] * gray.shape[1] * 0.01): # Si m√°s del 1% de los puntos son picos\n",
    "            score_spoofing += 35\n",
    "            razones.append(\"Patrones de alta frecuencia detectados (posible pantalla)\")\n",
    "\n",
    "        # T√âCNICA 2: An√°lisis de reflejos y brillo\n",
    "        _, thresh = cv2.threshold(gray, 245, 255, cv2.THRESH_BINARY)\n",
    "        pixeles_brillantes = cv2.countNonZero(thresh)\n",
    "        porcentaje_brillo = (pixeles_brillantes / gray.size) * 100\n",
    "        if porcentaje_brillo > 0.5: # Incluso un 0.5% de reflejo puro es sospechoso\n",
    "             score_spoofing += 25\n",
    "             razones.append(f\"Reflejos o √°reas sobreexpuestas detectadas ({porcentaje_brillo:.2f}%)\")\n",
    "\n",
    "        # T√âCNICA 3: Varianza de color (las fotos de fotos suelen ser m√°s planas)\n",
    "        pil_img = Image.open(ruta_imagen)\n",
    "        stat = ImageStat.Stat(pil_img)\n",
    "        varianza_promedio = sum(stat.var) / len(stat.var) if len(stat.var) > 0 else 0\n",
    "        if varianza_promedio < 1500: # Las fotos reales suelen tener alta varianza\n",
    "            score_spoofing += 20\n",
    "            razones.append(f\"Baja varianza de color ({varianza_promedio:.1f})\")\n",
    "\n",
    "        # T√âCNICA 4: Detecci√≥n de bordes rectos (marcos de tel√©fono o papel)\n",
    "        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=80, minLineLength=100, maxLineGap=10)\n",
    "        if lines is not None and len(lines) > 2:\n",
    "            score_spoofing += 20\n",
    "            razones.append(f\"Bordes rectos detectados ({len(lines)}), posible marco de pantalla\")\n",
    "\n",
    "        # Decisi√≥n final\n",
    "        es_spoofing = score_spoofing >= 65 # Umbral de decisi√≥n (ajustable)\n",
    "\n",
    "        detalles = {\n",
    "            \"score\": score_spoofing,\n",
    "            \"es_spoofing\": es_spoofing,\n",
    "            \"razones\": razones if es_spoofing else [\"Imagen parece aut√©ntica\"]\n",
    "        }\n",
    "\n",
    "        return es_spoofing, detalles\n",
    "\n",
    "    except Exception as e:\n",
    "        return False, {\"error\": f\"Excepci√≥n en an√°lisis de spoofing: {e}\"}\n",
    "\n",
    "\n",
    "# --- FUNCI√ìN PRINCIPAL DE IDENTIFICACI√ìN ---\n",
    "# Esta es la funci√≥n que ser√° llamada por el servidor Flask.\n",
    "\n",
    "def identificar_empleado(ruta_imagen_a_verificar, ruta_db):\n",
    "    \"\"\"\n",
    "    Funci√≥n de identificaci√≥n robusta:\n",
    "    1. Ejecuta un an√°lisis anti-spoofing sobre la imagen completa.\n",
    "    2. Si la imagen es aut√©ntica, procede con el reconocimiento facial usando DeepFace.\n",
    "    \"\"\"\n",
    "    print(\"\\nüì∏ Iniciando proceso de identificaci√≥n...\")\n",
    "\n",
    "    # PASO 1: An√°lisis anti-spoofing de la imagen completa\n",
    "    # ----------------------------------------------------\n",
    "    print(\"   - (1/2) Realizando an√°lisis de autenticidad de la imagen...\")\n",
    "    es_spoofing, detalles_spoofing = detectar_foto_de_foto(ruta_imagen_a_verificar)\n",
    "\n",
    "    if es_spoofing:\n",
    "        razones_str = \"; \".join(detalles_spoofing.get(\"razones\", []))\n",
    "        score = detalles_spoofing.get('score', 'N/A')\n",
    "        print(f\"   - üö´ SPOOFING DETECTADO (Score: {score}). Razones: {razones_str}\")\n",
    "        return f\"Error: Foto Falsa Detectada. {razones_str}\"\n",
    "\n",
    "    score = detalles_spoofing.get('score', 'N/A')\n",
    "    print(f\"   - ‚úÖ Imagen parece aut√©ntica (Score de spoofing: {score}).\")\n",
    "\n",
    "    # PASO 2: Reconocimiento Facial\n",
    "    # -----------------------------\n",
    "    print(\"   - (2/2) Realizando reconocimiento facial...\")\n",
    "    try:\n",
    "        # Usamos DeepFace.find para la identificaci√≥n 1-vs-N\n",
    "        dfs = DeepFace.find(\n",
    "            img_path=ruta_imagen_a_verificar,\n",
    "            db_path=ruta_db,\n",
    "            model_name='ArcFace',\n",
    "            detector_backend='retinaface',\n",
    "            enforce_detection=True,\n",
    "            silent=True\n",
    "        )\n",
    "\n",
    "        # Si no se encuentra ninguna coincidencia\n",
    "        if not dfs or dfs[0].empty:\n",
    "            print(\"   - ‚ùå Resultado: Desconocido. No se encontr√≥ ninguna coincidencia en la BD.\")\n",
    "            return \"Desconocido\"\n",
    "\n",
    "        # Se encontr√≥ una coincidencia, devolvemos el ID del empleado\n",
    "        identidad = dfs[0].iloc[0]\n",
    "        empleado_id = os.path.basename(os.path.dirname(identidad['identity']))\n",
    "        distancia = identidad['distance']\n",
    "\n",
    "        print(f\"   - ‚úÖ Resultado: Empleado identificado - ID: {empleado_id} (Distancia: {distancia:.3f})\")\n",
    "        return empleado_id\n",
    "\n",
    "    except ValueError as e:\n",
    "        # Error com√∫n si DeepFace no detecta una cara\n",
    "        if \"Face could not be detected\" in str(e):\n",
    "            print(\"   - ‚ùå Error de DeepFace: No se detect√≥ un rostro claro.\")\n",
    "            return \"Error: No se detect√≥ un rostro claro en la imagen.\"\n",
    "        print(f\"   - ‚ùå Error de DeepFace: {e}\")\n",
    "        return f\"Error en DeepFace: {e}\"\n",
    "    except Exception as e:\n",
    "        print(f\"   - ‚ùå Excepci√≥n inesperada en DeepFace: {e}\")\n",
    "        return f\"Error inesperado durante el reconocimiento: {e}\"\n",
    "\n",
    "\n",
    "# --- EJECUCI√ìN DEL PROCESO DE PREPARACI√ìN ---\n",
    "initialize_firebase()\n",
    "sync_face_database_from_firestore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49kpz3arzVca"
   },
   "source": [
    "## **Celda 3: Iniciar el Servidor API**\n",
    "### Prop√≥sito: Esta es la √∫ltima celda. Pone en marcha un servidor web (usando Flask) que expone nuestra funci√≥n identificar_empleado al mundo exterior.\n",
    "1. Configura pyngrok: Pide tu Authtoken para poder crear la URL p√∫blica.\n",
    "2. Define el Endpoint /identificar: Esta es la direcci√≥n espec√≠fica a la que tu app de Flutter har√° la llamada. Est√° programada para recibir un archivo de imagen (face_image).\n",
    "3. Inicia el T√∫nel y el Servidor: Crea la URL p√∫blica con pyngrok y la imprime en pantalla. Luego, arranca el servidor Flask, que se quedar√° esperando las peticiones de tu app. La ejecuci√≥n se quedar√° \"colgada\" en esta celda mientras el servidor est√© activo, lo cual es normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1096208,
     "status": "error",
     "timestamp": 1762826394180,
     "user": {
      "displayName": "Jorge Luis BRICE√ëO D√çAZ",
      "userId": "05586719358853567762"
     },
     "user_tz": 300
    },
    "id": "OOoeWZ1szoV0",
    "outputId": "19e4c60a-7b2c-4f87-d002-a9678cf59876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "‚úÖ ¬°API LISTA PARA USAR!\n",
      "   Tu URL p√∫blica para Flutter es: NgrokTunnel: \"https://c8a3aa65e9f9.ngrok-free.app\" -> \"http://localhost:5000\"\n",
      "   Recuerda a√±adir '/identificar' al final en tu c√≥digo de Flutter.\n",
      "============================================================\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [11/Nov/2025 01:44:22] \"\u001b[33mPOST /identificar HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∏ Iniciando proceso de identificaci√≥n...\n",
      "   - (1/2) Realizando an√°lisis de autenticidad de la imagen...\n",
      "   - ‚úÖ Imagen parece aut√©ntica (Score de spoofing: 35).\n",
      "   - (2/2) Realizando reconocimiento facial...\n",
      "   - ‚ùå Error de DeepFace: No item found in employee_face_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [11/Nov/2025 01:44:31] \"\u001b[33mPOST /identificar HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∏ Iniciando proceso de identificaci√≥n...\n",
      "   - (1/2) Realizando an√°lisis de autenticidad de la imagen...\n",
      "   - ‚úÖ Imagen parece aut√©ntica (Score de spoofing: 35).\n",
      "   - (2/2) Realizando reconocimiento facial...\n",
      "   - ‚ùå Error de DeepFace: No item found in employee_face_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [11/Nov/2025 01:44:37] \"\u001b[33mPOST /identificar HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∏ Iniciando proceso de identificaci√≥n...\n",
      "   - (1/2) Realizando an√°lisis de autenticidad de la imagen...\n",
      "   - ‚úÖ Imagen parece aut√©ntica (Score de spoofing: 35).\n",
      "   - (2/2) Realizando reconocimiento facial...\n",
      "   - ‚ùå Error de DeepFace: No item found in employee_face_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [11/Nov/2025 01:44:43] \"\u001b[33mPOST /identificar HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∏ Iniciando proceso de identificaci√≥n...\n",
      "   - (1/2) Realizando an√°lisis de autenticidad de la imagen...\n",
      "   - ‚úÖ Imagen parece aut√©ntica (Score de spoofing: 35).\n",
      "   - (2/2) Realizando reconocimiento facial...\n",
      "   - ‚ùå Error de DeepFace: No item found in employee_face_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [11/Nov/2025 01:45:03] \"\u001b[33mPOST /identificar HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∏ Iniciando proceso de identificaci√≥n...\n",
      "   - (1/2) Realizando an√°lisis de autenticidad de la imagen...\n",
      "   - ‚úÖ Imagen parece aut√©ntica (Score de spoofing: 35).\n",
      "   - (2/2) Realizando reconocimiento facial...\n",
      "   - ‚ùå Error de DeepFace: No item found in employee_face_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [11/Nov/2025 01:45:11] \"\u001b[33mPOST /identificar HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∏ Iniciando proceso de identificaci√≥n...\n",
      "   - (1/2) Realizando an√°lisis de autenticidad de la imagen...\n",
      "   - ‚úÖ Imagen parece aut√©ntica (Score de spoofing: 55).\n",
      "   - (2/2) Realizando reconocimiento facial...\n",
      "   - ‚ùå Error de DeepFace: No item found in employee_face_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [11/Nov/2025 01:45:32] \"\u001b[33mPOST /identificar HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∏ Iniciando proceso de identificaci√≥n...\n",
      "   - (1/2) Realizando an√°lisis de autenticidad de la imagen...\n",
      "   - ‚úÖ Imagen parece aut√©ntica (Score de spoofing: 35).\n",
      "   - (2/2) Realizando reconocimiento facial...\n",
      "   - ‚ùå Error de DeepFace: No item found in employee_face_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [11/Nov/2025 01:45:36] \"\u001b[33mPOST /identificar HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∏ Iniciando proceso de identificaci√≥n...\n",
      "   - (1/2) Realizando an√°lisis de autenticidad de la imagen...\n",
      "   - ‚úÖ Imagen parece aut√©ntica (Score de spoofing: 35).\n",
      "   - (2/2) Realizando reconocimiento facial...\n",
      "   - ‚ùå Error de DeepFace: No item found in employee_face_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [11/Nov/2025 01:45:40] \"\u001b[33mPOST /identificar HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∏ Iniciando proceso de identificaci√≥n...\n",
      "   - (1/2) Realizando an√°lisis de autenticidad de la imagen...\n",
      "   - ‚úÖ Imagen parece aut√©ntica (Score de spoofing: 35).\n",
      "   - (2/2) Realizando reconocimiento facial...\n",
      "   - ‚ùå Error de DeepFace: No item found in employee_face_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [11/Nov/2025 01:47:31] \"\u001b[33mPOST /identificar HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∏ Iniciando proceso de identificaci√≥n...\n",
      "   - (1/2) Realizando an√°lisis de autenticidad de la imagen...\n",
      "   - ‚úÖ Imagen parece aut√©ntica (Score de spoofing: 55).\n",
      "   - (2/2) Realizando reconocimiento facial...\n",
      "   - ‚ùå Error de DeepFace: No item found in employee_face_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [11/Nov/2025 01:48:07] \"\u001b[33mPOST /identificar HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∏ Iniciando proceso de identificaci√≥n...\n",
      "   - (1/2) Realizando an√°lisis de autenticidad de la imagen...\n",
      "   - ‚úÖ Imagen parece aut√©ntica (Score de spoofing: 35).\n",
      "   - (2/2) Realizando reconocimiento facial...\n",
      "   - ‚ùå Error de DeepFace: No item found in employee_face_db\n",
      "\n",
      "üîÑ Solicitud de sincronizaci√≥n manual recibida...\n",
      "\n",
      "üîÑ Sincronizando base de datos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [11/Nov/2025 01:48:55] \"POST /sync-database HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sincronizaci√≥n completada: 0 im√°genes para 4 empleados.\n",
      "\n",
      "üîÑ Solicitud de sincronizaci√≥n manual recibida...\n",
      "\n",
      "üîÑ Sincronizando base de datos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [11/Nov/2025 01:49:13] \"POST /sync-database HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sincronizaci√≥n completada: 0 im√°genes para 4 empleados.\n",
      "\n",
      "üîÑ Solicitud de sincronizaci√≥n manual recibida...\n",
      "\n",
      "üîÑ Sincronizando base de datos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [11/Nov/2025 01:50:38] \"POST /sync-database HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sincronizaci√≥n completada: 0 im√°genes para 4 empleados.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[0;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[0m\n\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3260\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_execution_succeeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_raised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3261\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_execution_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m                 \u001b[0;31m# Reset this so later displayed values do not modify the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notify_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \"\"\"Set the value of the trait by self.name for the instance.\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Celda 3: Iniciar el Servidor API con Flask y Ngrok\n",
    "# ==============================================================================\n",
    "# Prop√≥sito: Levantar un servidor web que tu app de Flutter pueda consumir.\n",
    "# Este servidor tendr√° un endpoint (/identificar) que recibe una imagen,\n",
    "# la procesa con la funci√≥n de IA (que incluye anti-spoofing) y devuelve el resultado.\n",
    "# ==============================================================================\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from pyngrok import ngrok, conf\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "# --- CONFIGURACI√ìN DE NGROK ---\n",
    "# Pega aqu√≠ tu Authtoken de Ngrok. Lo obtienes desde tu dashboard de ngrok.com\n",
    "NGROK_AUTH_TOKEN = \"2vVPYuy7nBsvhhxY2bTTjryatYH_3MVU7P1sQFUYKqcx1JJNh\"\n",
    "\n",
    "if not NGROK_AUTH_TOKEN or \"PEGA_AQUI\" in NGROK_AUTH_TOKEN:\n",
    "    print(\"‚ùå ERROR: Por favor, edita esta celda y pega tu Authtoken de Ngrok.\")\n",
    "else:\n",
    "    conf.get_default().auth_token = NGROK_AUTH_TOKEN\n",
    "\n",
    "    # --- CONFIGURACI√ìN DEL SERVIDOR FLASK ---\n",
    "    app = Flask(__name__)\n",
    "\n",
    "    # Carpeta para guardar temporalmente las im√°genes recibidas\n",
    "    uploads_dir = \"uploads\"\n",
    "    os.makedirs(uploads_dir, exist_ok=True)\n",
    "\n",
    "    # Definir el endpoint (la URL espec√≠fica que llamar√° Flutter)\n",
    "    @app.route('/identificar', methods=['POST'])\n",
    "    def endpoint_identificar():\n",
    "        if 'face_image' not in request.files:\n",
    "            return jsonify({\"error\": \"No se envi√≥ ning√∫n archivo de imagen.\", \"empleadoId\": None}), 400\n",
    "\n",
    "        file = request.files['face_image']\n",
    "        if not file or file.filename == '':\n",
    "            return jsonify({\"error\": \"Archivo inv√°lido o sin nombre.\", \"empleadoId\": None}), 400\n",
    "\n",
    "        # Guardar el archivo temporalmente\n",
    "        filename = str(uuid.uuid4()) + os.path.splitext(file.filename)[1]\n",
    "        filepath = os.path.join(uploads_dir, filename)\n",
    "        file.save(filepath)\n",
    "\n",
    "        # --- CAMBIO CLAVE AQU√ç ---\n",
    "        # Llamar a la funci√≥n de reconocimiento facial principal de la Celda 2\n",
    "        resultado_id = identificar_empleado(filepath, DB_PATH)\n",
    "\n",
    "        # Borrar el archivo temporal\n",
    "        os.remove(filepath)\n",
    "\n",
    "        # Devolver el resultado en formato JSON\n",
    "        # Esta l√≥gica ahora maneja los nuevos mensajes de error de forma m√°s expl√≠cita\n",
    "        if \"Error\" in resultado_id or \"Desconocido\" in resultado_id:\n",
    "            # Los logs ya se imprimen dentro de la funci√≥n `identificar_empleado`\n",
    "            # Devolvemos un c√≥digo 403 (Prohibido) si detectamos spoofing, 404 para otros errores.\n",
    "            status_code = 403 if \"Foto Falsa Detectada\" in resultado_id else 404\n",
    "            return jsonify({\"error\": resultado_id, \"empleadoId\": None}), status_code\n",
    "        else:\n",
    "            # Los logs de √©xito ya se imprimen dentro de la funci√≥n\n",
    "            return jsonify({\"empleadoId\": resultado_id, \"error\": None}), 200\n",
    "\n",
    "    @app.route('/sync-database', methods=['POST'])\n",
    "    def endpoint_sync():\n",
    "        print(\"\\nüîÑ Solicitud de sincronizaci√≥n manual recibida...\")\n",
    "        try:\n",
    "            sync_face_database_from_firestore()\n",
    "            return jsonify({\"message\": \"Sincronizaci√≥n completada.\"}), 200\n",
    "        except Exception as e:\n",
    "            return jsonify({\"error\": f\"Error al sincronizar: {e}\"}), 500\n",
    "\n",
    "    # --- INICIAR EL SERVIDOR Y EL T√öNEL ---\n",
    "    # Abre el t√∫nel de ngrok hacia el puerto 5000 (puerto por defecto de Flask)\n",
    "    public_url = ngrok.connect(5000, \"http\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚úÖ ¬°API LISTA PARA USAR!\")\n",
    "    print(f\"   Tu URL p√∫blica para Flutter es: {public_url}\")\n",
    "    print(\"   Recuerda a√±adir '/identificar' al final en tu c√≥digo de Flutter.\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Inicia la app de Flask. Se quedar√° corriendo hasta que detengas la celda.\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOjM+azYdIY7qjKLmj/QUpq",
   "provenance": [
    {
     "file_id": "11l1tebQBkTpH8DtUAX0BRocZsLaTWwpe",
     "timestamp": 1750361235594
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
